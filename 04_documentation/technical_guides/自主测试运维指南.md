# ğŸ¯ Fluss è‡ªä¸»æµ‹è¯•è¿ç»´æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç¯å¢ƒå¯åŠ¨ä¸æ£€æŸ¥](#ç¯å¢ƒå¯åŠ¨ä¸æ£€æŸ¥)
2. [åœºæ™¯ç‹¬ç«‹æ‰§è¡Œ](#åœºæ™¯ç‹¬ç«‹æ‰§è¡Œ)
3. [å®æ—¶ç›‘æ§æ–¹æ³•](#å®æ—¶ç›‘æ§æ–¹æ³•)
4. [æ•°æ®å˜æ›´è®¡ç®—](#æ•°æ®å˜æ›´è®¡ç®—)
5. [æ•…éšœæ’æŸ¥ä¸æ•°æ®è¡¥è´§](#æ•…éšœæ’æŸ¥ä¸æ•°æ®è¡¥è´§)
6. [æ€§èƒ½è°ƒä¼˜æŠ€å·§](#æ€§èƒ½è°ƒä¼˜æŠ€å·§)

---

## ğŸš€ ç¯å¢ƒå¯åŠ¨ä¸æ£€æŸ¥

### 1. å¯åŠ¨å®Œæ•´ç¯å¢ƒ
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# æ£€æŸ¥å…³é”®æœåŠ¡å¥åº·çŠ¶æ€
docker exec postgres-sgcc-source pg_isready -U sgcc_user
docker exec postgres-sgcc-sink pg_isready -U sgcc_user
```

### 2. éªŒè¯æ ¸å¿ƒç»„ä»¶
```bash
# æ£€æŸ¥Flussé›†ç¾¤çŠ¶æ€
curl -s http://localhost:9123/health

# æ£€æŸ¥Flink Web UI (å¯é€‰)
echo "è®¿é—® http://localhost:8091 æŸ¥çœ‹Flinkä½œä¸šçŠ¶æ€"

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "\dt"
docker exec postgres-sgcc-sink psql -U sgcc_user -d sgcc_dw_db -c "\dt"
```

---

## ğŸ® åœºæ™¯ç‹¬ç«‹æ‰§è¡Œ

### 1. åˆ›å»ºæ‰§è¡Œè„šæœ¬
```bash
# åˆ›å»ºåœºæ™¯æ‰§è¡Œç›®å½•
mkdir -p ~/fluss_scenarios

# åœºæ™¯1ï¼šé«˜é¢‘ç»´åº¦è¡¨æœåŠ¡
cat > ~/fluss_scenarios/run_scenario1.sh << 'EOF'
#!/bin/bash
echo "ğŸš€ å¼€å§‹æ‰§è¡Œåœºæ™¯1ï¼šé«˜é¢‘ç»´åº¦è¡¨æœåŠ¡"

# æ‰§è¡Œåœºæ™¯SQL
docker exec sql-client-sgcc /opt/flink/bin/sql-client.sh \
    -f /opt/sql/åœºæ™¯1_é«˜é¢‘ç»´åº¦è¡¨æœåŠ¡.sql

echo "âœ… åœºæ™¯1æ‰§è¡Œå®Œæˆï¼Œè¯·æ£€æŸ¥ä½œä¸šçŠ¶æ€"
EOF

chmod +x ~/fluss_scenarios/run_scenario1.sh
```

### 2. åˆ†æ®µæ‰§è¡Œæ–¹å¼
```bash
# æ–¹æ³•1ï¼šå®Œæ•´æ‰§è¡Œ
~/fluss_scenarios/run_scenario1.sh

# æ–¹æ³•2ï¼šåˆ†æ®µæ‰§è¡Œï¼ˆæ¨èï¼‰
# ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè¡¨ç»“æ„
cat > /tmp/step1_tables.sql << 'EOF'
SET 'sql-client.execution.result-mode' = 'TABLEAU';

-- 1. åˆ›å»ºCDCæºè¡¨
CREATE TABLE device_raw_stream (
    device_id STRING,
    voltage DOUBLE,
    current_val DOUBLE,
    temperature DOUBLE,
    power_output DOUBLE,
    efficiency DOUBLE,
    status STRING,
    alert_level STRING,
    event_time TIMESTAMP(3),
    WATERMARK FOR event_time AS event_time - INTERVAL '1' SECOND
) WITH (
    'connector' = 'postgres-cdc',
    'hostname' = 'postgres-sgcc-source',
    'port' = '5432',
    'username' = 'sgcc_user',
    'password' = 'sgcc_pass_2024',
    'database-name' = 'sgcc_source_db',
    'schema-name' = 'public',
    'table-name' = 'device_raw_data',
    'slot.name' = 'device_raw_slot',
    'decoding.plugin.name' = 'pgoutput'
);

-- 2. åˆ›å»ºFlussåˆ†å±‚è¡¨
CREATE CATALOG fluss_catalog WITH (
    'type' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

USE CATALOG fluss_catalog;
CREATE DATABASE IF NOT EXISTS fluss;
USE fluss;

-- ODSå±‚
CREATE TABLE IF NOT EXISTS ods_device_raw (
    device_id STRING PRIMARY KEY NOT ENFORCED,
    voltage DOUBLE,
    current_val DOUBLE,
    temperature DOUBLE,
    power_output DOUBLE,
    efficiency DOUBLE,
    status STRING,
    alert_level STRING,
    event_time TIMESTAMP(3)
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);
EOF

# æ‰§è¡Œè¡¨åˆ›å»º
docker cp /tmp/step1_tables.sql sql-client-sgcc:/opt/sql/
docker exec sql-client-sgcc /opt/flink/bin/sql-client.sh -f /opt/sql/step1_tables.sql
```

---

## ğŸ“Š å®æ—¶ç›‘æ§æ–¹æ³•

### 1. ä½œä¸šçŠ¶æ€ç›‘æ§
```bash
# åˆ›å»ºç›‘æ§è„šæœ¬
cat > ~/fluss_scenarios/monitor.sh << 'EOF'
#!/bin/bash

echo "=== ğŸ” Flussé›†ç¾¤ç›‘æ§ ==="
echo "å½“å‰æ—¶é—´: $(date)"
echo

# 1. æ£€æŸ¥Flinkä½œä¸šçŠ¶æ€
echo "ğŸ“‹ Flinkä½œä¸šåˆ—è¡¨:"
docker exec jobmanager-sgcc /opt/flink/bin/flink list 2>/dev/null | grep -E "(RUNNING|FAILED|FINISHED)"

echo
echo "ğŸ“Š Dockerå®¹å™¨çŠ¶æ€:"
docker-compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"

echo
echo "ğŸ’¾ æ•°æ®åº“è¿æ¥æµ‹è¯•:"
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "SELECT COUNT(*) FROM device_raw_data;" 2>/dev/null || echo "âŒ æºæ•°æ®åº“è¿æ¥å¤±è´¥"
docker exec postgres-sgcc-sink psql -U sgcc_user -d sgcc_dw_db -c "SELECT COUNT(*) FROM device_final_report;" 2>/dev/null || echo "âŒ ç›®æ ‡æ•°æ®åº“è¿æ¥å¤±è´¥"

EOF

chmod +x ~/fluss_scenarios/monitor.sh
```

### 2. æ•°æ®æµç›‘æ§
```bash
# åˆ›å»ºæ•°æ®æµç›‘æ§è„šæœ¬
cat > ~/fluss_scenarios/data_monitor.sql << 'EOF'
SET 'sql-client.execution.result-mode' = 'TABLEAU';

CREATE CATALOG fluss_catalog WITH (
    'type' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- æŸ¥çœ‹å„å±‚æ•°æ®é‡ï¼ˆå¿«ç…§ï¼‰
SELECT 'ODSå±‚' as layer, COUNT(*) as records FROM fluss_catalog.fluss.ods_device_raw;
EOF

# å®šæœŸæ‰§è¡Œæ•°æ®ç›‘æ§
watch -n 10 'docker cp ~/fluss_scenarios/data_monitor.sql sql-client-sgcc:/opt/sql/ && timeout 5 docker exec sql-client-sgcc /opt/flink/bin/sql-client.sh -f /opt/sql/data_monitor.sql 2>/dev/null | tail -5'
```

### 3. Web UIç›‘æ§
```bash
echo "ğŸŒ è®¿é—®ä»¥ä¸‹URLè¿›è¡Œå¯è§†åŒ–ç›‘æ§:"
echo "- Flink Web UI: http://localhost:8091"
echo "- ä½œä¸šç›‘æ§: http://localhost:8091/#/job/running"
echo "- Metricsç›‘æ§: http://localhost:8091/#/job/running/{job-id}/metrics"
```

---

## ğŸ”„ æ•°æ®å˜æ›´è®¡ç®—

### 1. å®æ—¶å˜æ›´ç›‘æ§
```sql
-- åˆ›å»ºå˜æ›´ç›‘æ§è¡¨
CREATE TABLE change_log_monitor (
    device_id STRING,
    old_efficiency DOUBLE,
    new_efficiency DOUBLE,
    change_type STRING,  -- INSERT, UPDATE, DELETE
    change_time TIMESTAMP(3),
    PRIMARY KEY (device_id, change_time) NOT ENFORCED
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- ç›‘æ§æ•ˆç‡å˜æ›´è¶…è¿‡é˜ˆå€¼çš„è®¾å¤‡
INSERT INTO change_log_monitor
SELECT 
    device_id,
    LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time) as old_efficiency,
    efficiency as new_efficiency,
    'UPDATE' as change_type,
    event_time as change_time
FROM fluss_catalog.fluss.ods_device_raw
WHERE ABS(efficiency - LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time)) > 0.05;
```

### 2. å¢é‡è®¡ç®—é€»è¾‘
```bash
# åˆ›å»ºå¢é‡è®¡ç®—è„šæœ¬
cat > ~/fluss_scenarios/incremental_compute.sql << 'EOF'
SET 'sql-client.execution.result-mode' = 'TABLEAU';

CREATE CATALOG fluss_catalog WITH (
    'type' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- åˆ›å»ºå¢é‡æ±‡æ€»è¡¨
CREATE TABLE IF NOT EXISTS incremental_summary (
    summary_id STRING PRIMARY KEY NOT ENFORCED,
    window_start TIMESTAMP(3),
    window_end TIMESTAMP(3),
    device_count BIGINT,
    avg_efficiency DOUBLE,
    efficiency_change_rate DOUBLE,
    alert_count BIGINT,
    compute_time TIMESTAMP(3)
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- 5åˆ†é’Ÿæ»šåŠ¨çª—å£å¢é‡è®¡ç®—
INSERT INTO fluss_catalog.fluss.incremental_summary
SELECT 
    CONCAT('INCR_', DATE_FORMAT(window_start, 'yyyyMMdd_HHmmss')) as summary_id,
    window_start,
    window_end,
    COUNT(DISTINCT device_id) as device_count,
    AVG(efficiency) as avg_efficiency,
    (MAX(efficiency) - MIN(efficiency)) / MIN(efficiency) as efficiency_change_rate,
    COUNT(CASE WHEN alert_level = 'H' THEN 1 END) as alert_count,
    CURRENT_TIMESTAMP as compute_time
FROM TABLE(
    TUMBLE(TABLE fluss_catalog.fluss.ods_device_raw, 
           DESCRIPTOR(event_time), 
           INTERVAL '5' MINUTE)
)
GROUP BY window_start, window_end;
EOF
```

### 3. å˜æ›´è§¦å‘å™¨
```bash
# åˆ›å»ºå˜æ›´å“åº”è„šæœ¬
cat > ~/fluss_scenarios/change_trigger.sql << 'EOF'
-- å¼‚å¸¸å˜æ›´è‡ªåŠ¨å“åº”
CREATE TABLE alert_response (
    alert_id STRING PRIMARY KEY NOT ENFORCED,
    device_id STRING,
    alert_type STRING,
    efficiency_drop DOUBLE,
    response_action STRING,
    trigger_time TIMESTAMP(3)
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- æ•ˆç‡ä¸‹é™è¶…è¿‡10%è‡ªåŠ¨è§¦å‘å‘Šè­¦
INSERT INTO alert_response
SELECT 
    CONCAT('ALERT_', device_id, '_', UNIX_TIMESTAMP()) as alert_id,
    device_id,
    'EFFICIENCY_DROP' as alert_type,
    ABS(efficiency - LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time)) as efficiency_drop,
    CASE 
        WHEN ABS(efficiency - LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time)) > 0.15 
        THEN 'IMMEDIATE_MAINTENANCE'
        WHEN ABS(efficiency - LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time)) > 0.10 
        THEN 'SCHEDULE_INSPECTION'
        ELSE 'MONITOR_CLOSELY'
    END as response_action,
    event_time as trigger_time
FROM fluss_catalog.fluss.ods_device_raw
WHERE ABS(efficiency - LAG(efficiency) OVER (PARTITION BY device_id ORDER BY event_time)) > 0.10;
EOF
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥ä¸æ•°æ®è¡¥è´§

### 1. å¸¸è§æ•…éšœè¯Šæ–­
```bash
# åˆ›å»ºæ•…éšœè¯Šæ–­è„šæœ¬
cat > ~/fluss_scenarios/diagnose.sh << 'EOF'
#!/bin/bash

echo "ğŸ” å¼€å§‹æ•…éšœè¯Šæ–­..."

# 1. æ£€æŸ¥ä½œä¸šçŠ¶æ€
echo "=== Flinkä½œä¸šçŠ¶æ€ ==="
docker exec jobmanager-sgcc /opt/flink/bin/flink list | grep -E "(FAILED|RESTARTING|CANCELED)"

# 2. æ£€æŸ¥å®¹å™¨æ—¥å¿—
echo "=== å®¹å™¨é”™è¯¯æ—¥å¿— ==="
docker logs coordinator-server-sgcc --tail 20 2>&1 | grep -i error
docker logs jobmanager-sgcc --tail 20 2>&1 | grep -i error

# 3. æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "=== æ•°æ®åº“è¿æ¥æµ‹è¯• ==="
docker exec postgres-sgcc-source pg_isready -U sgcc_user || echo "âŒ æºæ•°æ®åº“è¿æ¥å¤±è´¥"
docker exec postgres-sgcc-sink pg_isready -U sgcc_user || echo "âŒ ç›®æ ‡æ•°æ®åº“è¿æ¥å¤±è´¥"

# 4. æ£€æŸ¥CDCæ§½ä½çŠ¶æ€
echo "=== CDCå¤åˆ¶æ§½çŠ¶æ€ ==="
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "SELECT slot_name, active, restart_lsn FROM pg_replication_slots;"

echo "âœ… è¯Šæ–­å®Œæˆ"
EOF

chmod +x ~/fluss_scenarios/diagnose.sh
```

### 2. æ•°æ®è¡¥è´§ç­–ç•¥
```bash
# åˆ›å»ºæ•°æ®è¡¥è´§è„šæœ¬
cat > ~/fluss_scenarios/data_recovery.sh << 'EOF'
#!/bin/bash

echo "ğŸ”„ å¼€å§‹æ•°æ®è¡¥è´§..."

# 1. åœæ­¢ç›¸å…³ä½œä¸š
echo "åœæ­¢ç°æœ‰ä½œä¸š..."
docker exec jobmanager-sgcc /opt/flink/bin/flink list | grep RUNNING | awk '{print $4}' | while read job_id; do
    docker exec jobmanager-sgcc /opt/flink/bin/flink cancel $job_id
done

# 2. æ¸…ç†ç›®æ ‡è¡¨ï¼ˆå¯é€‰ï¼‰
echo "æ¸…ç†ç›®æ ‡è¡¨..."
docker exec postgres-sgcc-sink psql -U sgcc_user -d sgcc_dw_db -c "TRUNCATE TABLE device_final_report;"

# 3. é‡ç½®CDCæ§½ä½
echo "é‡ç½®CDCæ§½ä½..."
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "SELECT pg_drop_replication_slot('device_raw_slot');" || true
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "SELECT * FROM pg_create_logical_replication_slot('device_raw_slot', 'pgoutput');"

# 4. é‡æ–°å¯åŠ¨æ•°æ®æµ
echo "é‡æ–°å¯åŠ¨æ•°æ®æµ..."
docker exec sql-client-sgcc /opt/flink/bin/sql-client.sh -f /opt/sql/åœºæ™¯1_é«˜é¢‘ç»´åº¦è¡¨æœåŠ¡.sql

echo "âœ… æ•°æ®è¡¥è´§å®Œæˆ"
EOF

chmod +x ~/fluss_scenarios/data_recovery.sh
```

### 3. å†å²æ•°æ®å›æ”¾
```sql
-- å†å²æ•°æ®å›æ”¾è„šæœ¬
CREATE TABLE historical_replay (
    device_id STRING,
    voltage DOUBLE,
    efficiency DOUBLE,
    replay_timestamp TIMESTAMP(3),
    original_timestamp TIMESTAMP(3),
    PRIMARY KEY (device_id, replay_timestamp) NOT ENFORCED
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

-- å›æ”¾æŒ‡å®šæ—¶é—´æ®µçš„æ•°æ®
INSERT INTO historical_replay
SELECT 
    device_id,
    voltage,
    efficiency,
    CURRENT_TIMESTAMP as replay_timestamp,
    event_time as original_timestamp
FROM fluss_catalog.fluss.ods_device_raw
WHERE event_time BETWEEN '2024-01-01 00:00:00' AND '2024-01-01 23:59:59';
```

---

## âš¡ æ€§èƒ½è°ƒä¼˜æŠ€å·§

### 1. è°ƒä¼˜å‚æ•°é…ç½®
```bash
# åˆ›å»ºè°ƒä¼˜é…ç½®
cat > ~/fluss_scenarios/performance_tuning.sql << 'EOF'
-- è®¾ç½®æ€§èƒ½ä¼˜åŒ–å‚æ•°
SET 'execution.checkpointing.interval' = '30s';
SET 'execution.checkpointing.mode' = 'EXACTLY_ONCE';
SET 'state.backend' = 'rocksdb';
SET 'state.checkpoints.dir' = 'file:///opt/flink/checkpoints';
SET 'parallelism.default' = '4';
SET 'table.exec.resource.default-parallelism' = '4';
SET 'table.exec.mini-batch.enabled' = 'true';
SET 'table.exec.mini-batch.allow-latency' = '1s';
SET 'table.exec.mini-batch.size' = '1000';
EOF
```

### 2. ç›‘æ§å…³é”®æŒ‡æ ‡
```bash
# åˆ›å»ºæ€§èƒ½ç›‘æ§è„šæœ¬
cat > ~/fluss_scenarios/performance_monitor.sh << 'EOF'
#!/bin/bash

echo "ğŸ“ˆ æ€§èƒ½ç›‘æ§æŠ¥å‘Š"
echo "æ—¶é—´: $(date)"
echo

# 1. å†…å­˜ä½¿ç”¨æƒ…å†µ
echo "=== å†…å­˜ä½¿ç”¨ ==="
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

# 2. ä½œä¸šååé‡ï¼ˆéœ€è¦Flink Metrics APIï¼‰
echo "=== ååé‡æŒ‡æ ‡ ==="
curl -s http://localhost:8091/jobs/overview 2>/dev/null | jq '.jobs[] | {id: .jid, name: .name, state: .state}' || echo "æ— æ³•è·å–ä½œä¸šæŒ‡æ ‡"

# 3. æ•°æ®å»¶è¿Ÿæ£€æŸ¥
echo "=== æ•°æ®å»¶è¿Ÿæ£€æŸ¥ ==="
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "SELECT COUNT(*), MAX(event_time) FROM device_raw_data;" 2>/dev/null

echo "âœ… ç›‘æ§å®Œæˆ"
EOF

chmod +x ~/fluss_scenarios/performance_monitor.sh
```

---

## ğŸ¯ å®æ“ç¤ºä¾‹

### å®Œæ•´çš„æµ‹è¯•æµç¨‹
```bash
# 1. å¯åŠ¨ç¯å¢ƒ
docker-compose up -d
sleep 30

# 2. æ‰§è¡Œç›‘æ§
~/fluss_scenarios/monitor.sh

# 3. è¿è¡Œåœºæ™¯
~/fluss_scenarios/run_scenario1.sh

# 4. å®æ—¶ç›‘æ§æ•°æ®
~/fluss_scenarios/performance_monitor.sh

# 5. å¦‚é‡æ•…éšœï¼Œæ‰§è¡Œè¯Šæ–­
~/fluss_scenarios/diagnose.sh

# 6. å¦‚éœ€æ•°æ®è¡¥è´§
~/fluss_scenarios/data_recovery.sh
```

### æ‰‹åŠ¨æµ‹è¯•æ•°æ®å˜æ›´
```sql
-- æ‰‹åŠ¨æ’å…¥æµ‹è¯•æ•°æ®
INSERT INTO insert_to_postgres_source VALUES
('MANUAL_001', 235.5, 150.0, 45.2, 350.8, 0.96, 'A', 'H', CURRENT_TIMESTAMP);

-- æ‰‹åŠ¨æ›´æ–°æ•°æ®æµ‹è¯•å¢é‡è®¡ç®—
UPDATE insert_to_postgres_source 
SET efficiency = 0.88, alert_level = 'M' 
WHERE device_id = 'MANUAL_001';

-- æ‰‹åŠ¨åˆ é™¤æ•°æ®æµ‹è¯•
DELETE FROM insert_to_postgres_source WHERE device_id = 'MANUAL_001';
```

---

**ğŸ‰ ç°åœ¨æ‚¨å·²ç»æ‹¥æœ‰äº†å®Œæ•´çš„è‡ªä¸»æµ‹è¯•å’Œè¿ç»´èƒ½åŠ›ï¼**

**æ ¸å¿ƒè¦ç‚¹**:
- âœ… **åˆ†æ®µæ‰§è¡Œ**: é¿å…ä¸€æ¬¡æ€§æ‰§è¡Œå¤§è„šæœ¬
- âœ… **å®æ—¶ç›‘æ§**: æŒç»­è§‚å¯Ÿæ•°æ®æµçŠ¶æ€  
- âœ… **æ•…éšœè‡ªæ„ˆ**: å¿«é€Ÿè¯Šæ–­å’Œæ¢å¤èƒ½åŠ›
- âœ… **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚ä¼˜åŒ–å‚æ•° 