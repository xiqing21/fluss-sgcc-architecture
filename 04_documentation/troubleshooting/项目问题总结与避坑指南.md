# Fluss SGCC架构测试项目问题总结与避坑指南

## 📋 项目概述
- **项目名称**: Fluss SGCC实时数据架构
- **技术栈**: Flink + Fluss + PostgreSQL CDC + Docker
- **数据链路**: PostgreSQL CDC → Fluss ODS → DWD → DWS → ADS → PostgreSQL Sink
- **测试日期**: 2025年1月

---

## 🚨 问题分类总结

### 1. 环境配置与部署问题

#### 1.1 Docker文件映射混淆
**问题描述**: 用户对Docker volume映射机制不清楚，怀疑文件同步有问题
- **现象**: 修改了本地`./fluss/sql/1_fluss_all_chain.sql`文件，担心容器内看不到
- **解决方案**: 确认`./fluss/sql:/opt/sql`映射工作正常，实时同步
- **避坑建议**: 
  - 使用`docker exec -it container_name ls /opt/sql`验证映射
  - 修改文件后可通过`docker exec -it container_name cat /opt/sql/filename`确认同步

#### 1.2 SQL Client执行参数错误
**问题描述**: 使用错误的`-i`参数导致"Failed to initialize from sql script"
- **错误命令**: `sql-client.sh embedded -i /opt/sql/1_fluss_all_chain.sql`
- **正确命令**: `sql-client.sh embedded -f /opt/sql/1_fluss_all_chain.sql`
- **避坑建议**: 
  - `-f`: 执行SQL文件后退出
  - `-i`: 初始化SQL文件后保持交互式session
  - 根据需求选择合适的参数

### 2. SQL语法兼容性问题

#### 2.1 Flink SQL不支持VIEW
**问题描述**: `CREATE VIEW`语句执行失败
- **错误**: `CREATE VIEW xx AS SELECT...`
- **原因**: Fluss catalog不支持视图操作
- **解决方案**: 移除所有VIEW定义，直接使用TABLE
- **避坑建议**: 在Flink SQL中避免使用VIEW，改用临时表或直接嵌套查询

#### 2.2 日期时间函数兼容性
**问题描述**: 多个日期时间函数语法错误
- **DATE()函数**: `DATE(created_at)` → `CAST(created_at AS DATE)`
- **DATEDIFF()函数**: `DATEDIFF(CURRENT_DATE, DATE(created_at))` → `TIMESTAMPDIFF(DAY, CAST(created_at AS DATE), CURRENT_DATE)`
- **避坑建议**: 
  - 使用标准SQL函数，避免MySQL特有函数
  - 日期转换使用`CAST`而非特定函数
  - 日期差值计算使用`TIMESTAMPDIFF`

#### 2.3 字符串连接类型匹配
**问题描述**: `CONCAT`函数类型不匹配
- **错误**: `CONCAT(username, ' (', segment_type, ')')`
- **解决方案**: 添加类型转换`CONCAT(CAST(username AS STRING), ' (', CAST(segment_type AS STRING), ')')`
- **避坑建议**: 字符串连接前确保所有参数都是STRING类型

#### 2.4 数据类型不兼容
**问题描述**: PostgreSQL sink不支持`TIMESTAMP_LTZ(3)`
- **错误**: `update_time TIMESTAMP_LTZ(3)`
- **解决方案**: 改为`update_time TIMESTAMP(3)`
- **避坑建议**: 
  - 检查目标数据库支持的数据类型
  - 尽量使用标准SQL数据类型

### 3. Catalog上下文问题

#### 3.1 对象引用错误
**问题描述**: "Object 'ads_realtime_dashboard' not found"
- **原因**: 缺少完整的catalog路径
- **解决方案**: 使用全限定名`fluss.fluss.ads_realtime_dashboard`
- **避坑建议**: 
  - 在Flink SQL中使用`catalog.database.table`格式
  - 使用`USE CATALOG catalog_name`切换上下文
  - 用`SHOW TABLES`验证表是否存在

### 4. 资源管理问题

#### 4.1 任务堆积导致资源耗尽
**问题描述**: 多次SQL执行导致"No more available task slots"
- **原因**: 每次执行都创建新任务，未清理旧任务
- **解决方案**: 执行前重启Flink集群`docker-compose restart jobmanager taskmanager-1 taskmanager-2`
- **避坑建议**: 
  - 测试前清理环境，避免任务堆积
  - 监控任务状态，及时清理异常任务
  - 考虑增加task slots或优化并发度

### 5. 会话管理问题

#### 5.1 自动退出session困扰
**问题描述**: `-f`参数执行完毕后自动退出，无法继续调试
- **用户痛点**: 既要批量执行SQL，又要保持交互式session
- **解决方案**: 
  - 使用`-i`参数: 先执行SQL文件，再保持交互式
  - 创建`smart_sql_execution.sh`脚本整合功能
- **避坑建议**: 
  - 开发调试时使用`-i`参数
  - 生产部署时使用`-f`参数
  - 准备不同场景的执行脚本

### 6. 数据逻辑问题

#### 6.1 业务状态不匹配
**问题描述**: 源数据订单状态为'PAID'/'PENDING'，但业务计算需要'completed'
- **现象**: 只有`ads_realtime_dashboard`有数据，其他表为空
- **解决方案**: 更新源数据订单状态为'completed'
- **避坑建议**: 
  - 确认业务逻辑与测试数据匹配
  - 检查过滤条件是否正确
  - 验证数据流各层级的转换逻辑

---

## 🛠️ 最佳实践建议

### 开发阶段
1. **环境隔离**: 使用Docker确保环境一致性
2. **SQL验证**: 分层验证SQL语法和逻辑
3. **增量测试**: 逐步测试ODS→DWD→DWS→ADS链路
4. **日志监控**: 实时查看Flink任务日志

### 测试阶段
1. **数据准备**: 确保测试数据符合业务逻辑
2. **资源清理**: 每次测试前重启服务清理状态
3. **结果验证**: 检查每层数据转换结果
4. **性能测试**: 验证数据延迟和吞吐量

### 部署阶段
1. **参数优化**: 根据数据量调整并发度和资源
2. **监控告警**: 建立完善的监控体系
3. **故障恢复**: 准备故障处理和恢复方案
4. **文档维护**: 更新部署和运维文档

---

## 📚 常用命令速查

### 环境管理
```bash
# 重启Flink集群
docker-compose restart jobmanager taskmanager-1 taskmanager-2

# 查看任务状态
docker exec -it sql-client-sgcc /opt/flink/bin/flink list

# 智能SQL执行（推荐）
./smart_sql_execution.sh
```

### 数据验证
```bash
# 快速验证数据
./quick_verify_data.sh

# 完整测试周期
./complete_test_cycle.sh
```

### 调试查看
```bash
# 查看表结构
SHOW TABLES;
DESC table_name;

# 查看数据
SELECT * FROM table_name LIMIT 10;
```

---

## 🎯 核心避坑总结

1. **语法兼容性**: 使用标准SQL，避免方言特性
2. **资源管理**: 测试前清理环境，避免任务堆积
3. **上下文管理**: 使用完整的catalog.database.table引用
4. **数据逻辑**: 确保测试数据与业务逻辑匹配
5. **会话管理**: 根据场景选择合适的执行方式
6. **类型匹配**: 注意数据类型兼容性，特别是时间和字符串类型

---

## 📈 项目成果

✅ **成功构建**: PostgreSQL CDC → Fluss ODS → DWD → DWS → ADS → PostgreSQL Sink完整链路
✅ **实时处理**: 7个Flink任务稳定运行
✅ **数据验证**: 三个ADS表正常输出业务指标
✅ **工具完善**: 提供完整的测试和管理脚本

**总数据量**: 5个订单，总金额406.25，涵盖2个用户，按小时聚合2个时间窗口

---

**文档更新时间**: 2025年1月16日
**版本**: v1.0 