#!/bin/bash

# ğŸš€ SGCC Fluss ä¸€é”®å¯åŠ¨å…¨é“¾è·¯éªŒè¯æµ‹è¯•è„šæœ¬
# åŠŸèƒ½ï¼šç¯å¢ƒå¯åŠ¨ + ä¸šåŠ¡SQLæ‰§è¡Œ + å…¨é“¾è·¯æ•°æ®éªŒè¯ + å¢åˆ æ”¹æµ‹è¯• + æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
# ä½œè€…ï¼šAIåŠ©æ‰‹ & ç”¨æˆ·åä½œå¼€å‘
# ç‰ˆæœ¬ï¼šv1.0
# æ—¥æœŸï¼š$(date +%Y-%m-%d)

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æµ‹è¯•é…ç½®
TEST_START_TIME=$(date +%s)
TEST_REPORT_DIR="test-reports"
TEST_REPORT_FILE="$TEST_REPORT_DIR/full_test_report_$(date +%Y%m%d_%H%M%S).md"

# åˆ›å»ºæµ‹è¯•æŠ¥å‘Šç›®å½•
mkdir -p "$TEST_REPORT_DIR"

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
    echo "[INFO] $1" >> "$TEST_REPORT_FILE"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
    echo "[SUCCESS] $1" >> "$TEST_REPORT_FILE"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
    echo "[WARNING] $1" >> "$TEST_REPORT_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
    echo "[ERROR] $1" >> "$TEST_REPORT_FILE"
}

# æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
declare -A metrics
metrics[total_records_processed]=0
metrics[total_jobs_created]=0
metrics[total_test_scenarios]=0
metrics[successful_scenarios]=0
metrics[failed_scenarios]=0

# åˆå§‹åŒ–æµ‹è¯•æŠ¥å‘Š
init_test_report() {
    cat > "$TEST_REPORT_FILE" << EOF
# ğŸš€ SGCC Fluss å…¨é“¾è·¯éªŒè¯æµ‹è¯•æŠ¥å‘Š

**æµ‹è¯•å¼€å§‹æ—¶é—´**: $(date)  
**æµ‹è¯•ç¯å¢ƒ**: Docker Compose + Fluss 0.7.0 + Flink 1.20 + PostgreSQL  
**æµ‹è¯•ç‰ˆæœ¬**: v1.0  

---

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

EOF
}

# ç¯å¢ƒå¯åŠ¨å‡½æ•°ï¼ˆå¢å¼ºæ¸…ç†ç‰ˆï¼‰
start_environment() {
    log_info "ğŸŒŸ æ­¥éª¤1: å¯åŠ¨æµ‹è¯•ç¯å¢ƒï¼ˆå«å½»åº•æ¸…ç†ï¼‰"
    
    # ä¼˜é›…åœæ­¢æ‰€æœ‰Flinkä»»åŠ¡
    log_info "ä¼˜é›…åœæ­¢æ‰€æœ‰Flinkä»»åŠ¡..."
    local running_jobs=$(docker exec jobmanager-sgcc /opt/flink/bin/flink list -r 2>/dev/null)
    
    if [[ "$running_jobs" != *"No running jobs"* ]] && [[ -n "$running_jobs" ]]; then
        local job_ids=$(echo "$running_jobs" | grep -oE '[a-f0-9]{32}')
        local job_count=0
        
        for job_id in $job_ids; do
            log_info "åœæ­¢ä»»åŠ¡: $job_id"
            docker exec jobmanager-sgcc /opt/flink/bin/flink cancel "$job_id" >/dev/null 2>&1
            sleep 2
            job_count=$((job_count + 1))
        done
        
        if [[ $job_count -gt 0 ]]; then
            log_success "âœ… å·²åœæ­¢ $job_count ä¸ªFlinkä»»åŠ¡"
        fi
    fi
    
    # åœæ­¢ç°æœ‰ç¯å¢ƒ
    log_info "åœæ­¢ç°æœ‰ç¯å¢ƒ..."
    docker-compose down > /dev/null 2>&1
    sleep 10
    
    # å½»åº•æ¸…ç†Flussç›¸å…³æ•°æ®å·ï¼ˆè§£å†³metadataé—®é¢˜ï¼‰
    log_info "å½»åº•æ¸…ç†Fluss metadataå’Œæ•°æ®å·..."
    local volumes_to_remove=(
        "fluss_coordinator_data"
        "fluss_tablet_data"
        "flink_checkpoints"
        "flink_savepoints"
    )
    
    for volume in "${volumes_to_remove[@]}"; do
        if docker volume ls -q | grep -q "^${volume}$"; then
            log_info "åˆ é™¤å·: $volume"
            docker volume rm "$volume" > /dev/null 2>&1
        fi
    done
    
    # æ¸…ç†æœªä½¿ç”¨çš„å·
    log_info "æ¸…ç†æœªä½¿ç”¨çš„Dockerå·..."
    docker volume prune -f > /dev/null 2>&1
    
    # æ¸…ç†ç³»ç»Ÿç¼“å­˜
    log_info "æ¸…ç†Dockerç³»ç»Ÿç¼“å­˜..."
    docker system prune -f > /dev/null 2>&1
    
    # å¯åŠ¨ç¯å¢ƒ
    log_info "å¯åŠ¨Docker Composeç¯å¢ƒ..."
    if docker-compose up -d; then
        log_success "ç¯å¢ƒå¯åŠ¨æˆåŠŸ"
    else
        log_error "ç¯å¢ƒå¯åŠ¨å¤±è´¥"
        exit 1
    fi
    
    # ç­‰å¾…æœåŠ¡å°±ç»ª
    log_info "ç­‰å¾…æœåŠ¡å°±ç»ª..."
    sleep 45
    
    # éªŒè¯æœåŠ¡çŠ¶æ€
    log_info "éªŒè¯æœåŠ¡çŠ¶æ€..."
    local services=("coordinator-server-sgcc" "tablet-server-sgcc" "jobmanager-sgcc" "taskmanager-sgcc-1" "postgres-sgcc-source" "postgres-sgcc-sink")
    for service in "${services[@]}"; do
        if docker ps --format "table {{.Names}}" | grep -q "$service"; then
            log_success "âœ… $service æœåŠ¡æ­£å¸¸"
        else
            log_error "âŒ $service æœåŠ¡å¼‚å¸¸"
        fi
    done
}

# æ‰§è¡ŒSQLè„šæœ¬å‡½æ•°
execute_sql_script() {
    local script_file="$1"
    local description="$2"
    
    log_info "æ‰§è¡Œ: $description"
    
    local start_time=$(date +%s)
    
    if docker exec -i sql-client-sgcc /opt/flink/bin/sql-client.sh embedded < "$script_file"; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        log_success "âœ… $description å®Œæˆ (è€—æ—¶: ${duration}ç§’)"
        metrics[total_jobs_created]=$((metrics[total_jobs_created] + 1))
        return 0
    else
        log_error "âŒ $description å¤±è´¥"
        return 1
    fi
}

# æ•°æ®éªŒè¯å‡½æ•°
validate_data() {
    log_info "ğŸ” æ­¥éª¤2: æ•°æ®éªŒè¯"
    
    # éªŒè¯PostgreSQLæºæ•°æ®
    log_info "éªŒè¯PostgreSQLæºæ•°æ®..."
    local source_count=$(docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -t -c "SELECT COUNT(*) FROM sgcc_power.power_monitoring;" 2>/dev/null | tr -d ' ')
    if [[ "$source_count" -gt 0 ]]; then
        log_success "âœ… æºæ•°æ®è¡¨è®°å½•æ•°: $source_count"
        metrics[total_records_processed]=$((metrics[total_records_processed] + source_count))
    else
        log_warning "âš ï¸ æºæ•°æ®è¡¨æ— æ•°æ®"
    fi
    
    # éªŒè¯Flusså„å±‚æ•°æ®
    log_info "éªŒè¯Flussæ•°æ®æ¹–å„å±‚æ•°æ®..."
    
    # åˆ›å»ºéªŒè¯SQLè„šæœ¬
    cat > /tmp/validate_fluss_data.sql << 'EOF'
CREATE CATALOG fluss_catalog WITH (
    'type' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);

USE CATALOG fluss_catalog;

-- éªŒè¯ODSå±‚
SELECT 'ODS power_monitoring' as layer, COUNT(*) as count FROM sgcc_ods.power_monitoring_ods;

-- éªŒè¯DWDå±‚
SELECT 'DWD power_monitoring' as layer, COUNT(*) as count FROM sgcc_dwd.power_monitoring_dwd;

-- éªŒè¯DWSå±‚
SELECT 'DWS power_summary' as layer, COUNT(*) as count FROM sgcc_dws.power_summary_dws;

-- éªŒè¯ADSå±‚
SELECT 'ADSæ™ºèƒ½æŠ¥å‘Š' as layer, COUNT(*) as count FROM sgcc_ads.power_intelligence_report;

-- éªŒè¯æœ€æ–°æ•°æ®
SELECT 'DWDæœ€æ–°æ•°æ®' as info, equipment_id, voltage_a, current_a, monitoring_time 
FROM sgcc_dwd.power_monitoring_dwd 
ORDER BY monitoring_time DESC LIMIT 5;
EOF
    
    # æ‰§è¡ŒéªŒè¯
    if execute_sql_script "/tmp/validate_fluss_data.sql" "Flussæ•°æ®æ¹–éªŒè¯"; then
        log_success "âœ… Flussæ•°æ®æ¹–éªŒè¯å®Œæˆ"
    else
        log_error "âŒ Flussæ•°æ®æ¹–éªŒè¯å¤±è´¥"
    fi
    
    # éªŒè¯PostgreSQLç›®æ ‡æ•°æ®
    log_info "éªŒè¯PostgreSQLç›®æ ‡æ•°æ®..."
    local target_count=$(docker exec postgres-sgcc-sink psql -U sgcc_user -d sgcc_dw_db -t -c "SELECT COUNT(*) FROM power_summary_report;" 2>/dev/null | tr -d ' ')
    if [[ "$target_count" -gt 0 ]]; then
        log_success "âœ… ç›®æ ‡æ•°æ®è¡¨è®°å½•æ•°: $target_count"
        metrics[total_records_processed]=$((metrics[total_records_processed] + target_count))
    else
        log_warning "âš ï¸ ç›®æ ‡æ•°æ®è¡¨æ— æ•°æ®"
    fi
}

# åœæ­¢æ‰€æœ‰Flinkä»»åŠ¡
stop_all_flink_jobs() {
    log_info "ğŸ›‘ åœæ­¢æ‰€æœ‰Flinkä»»åŠ¡..."
    
    # è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
    local running_jobs=$(docker exec jobmanager-sgcc /opt/flink/bin/flink list -r 2>/dev/null)
    
    if [[ "$running_jobs" == *"No running jobs"* ]] || [[ -z "$running_jobs" ]]; then
        log_info "æ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡éœ€è¦åœæ­¢"
        return 0
    fi
    
    # æå–ä»»åŠ¡IDå¹¶åœæ­¢
    local job_ids=$(echo "$running_jobs" | grep -oE '[a-f0-9]{32}')
    local job_count=0
    
    for job_id in $job_ids; do
        log_info "åœæ­¢ä»»åŠ¡: $job_id"
        docker exec jobmanager-sgcc /opt/flink/bin/flink cancel "$job_id" >/dev/null 2>&1
        sleep 2
        job_count=$((job_count + 1))
    done
    
    if [[ $job_count -gt 0 ]]; then
        log_success "âœ… å·²åœæ­¢ $job_count ä¸ªä»»åŠ¡"
    fi
    
    # ç­‰å¾…ä»»åŠ¡å®Œå…¨åœæ­¢
    sleep 10
}

# ä¸šåŠ¡åœºæ™¯æµ‹è¯•å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
run_business_scenarios() {
    log_info "ğŸ¯ æ­¥éª¤3: ä¸šåŠ¡åœºæ™¯æµ‹è¯•ï¼ˆå«ä»»åŠ¡ç®¡ç†ï¼‰"
    
    local scenarios=(
        "business-scenarios/åœºæ™¯1_é«˜é¢‘ç»´åº¦è¡¨æœåŠ¡.sql:åœºæ™¯1_é«˜é¢‘ç»´åº¦è¡¨æœåŠ¡"
        "business-scenarios/åœºæ™¯2_æ™ºèƒ½åŒæµJOIN.sql:åœºæ™¯2_æ™ºèƒ½åŒæµJOIN"
        "business-scenarios/åœºæ™¯3_æ—¶é—´æ—…è¡ŒæŸ¥è¯¢.sql:åœºæ™¯3_æ—¶é—´æ—…è¡ŒæŸ¥è¯¢"
        "business-scenarios/åœºæ™¯4_æŸ±çŠ¶æµä¼˜åŒ–.sql:åœºæ™¯4_æŸ±çŠ¶æµä¼˜åŒ–"
    )
    
    for scenario in "${scenarios[@]}"; do
        local script_file="${scenario%:*}"
        local description="${scenario#*:}"
        
        metrics[total_test_scenarios]=$((metrics[total_test_scenarios] + 1))
        
        log_info "ğŸ¯ å¼€å§‹æ‰§è¡Œ: $description"
        
        if execute_sql_script "$script_file" "$description"; then
            metrics[successful_scenarios]=$((metrics[successful_scenarios] + 1))
            
            # åœºæ™¯æ‰§è¡ŒæˆåŠŸåç­‰å¾…ä¸€æ®µæ—¶é—´è®©ä»»åŠ¡ç¨³å®šè¿è¡Œ
            log_info "ç­‰å¾…åœºæ™¯ä»»åŠ¡ç¨³å®šè¿è¡Œ (20ç§’)..."
            sleep 20
            
            # åœæ­¢å½“å‰åœºæ™¯çš„æ‰€æœ‰ä»»åŠ¡
            log_info "ğŸ›‘ æ¸…ç†åœºæ™¯ä»»åŠ¡ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªåœºæ™¯..."
            stop_all_flink_jobs
            
        else
            metrics[failed_scenarios]=$((metrics[failed_scenarios] + 1))
            log_error "âŒ åœºæ™¯æ‰§è¡Œå¤±è´¥ï¼Œåœæ­¢æ‰€æœ‰ä»»åŠ¡åç»§ç»­ä¸‹ä¸€ä¸ªåœºæ™¯"
            stop_all_flink_jobs
        fi
        
        # åœºæ™¯é—´æš‚åœ
        log_info "åœºæ™¯é—´ç­‰å¾… (15ç§’)..."
        sleep 15
    done
}

# å¢åˆ æ”¹æµ‹è¯•å‡½æ•°
run_crud_operations() {
    log_info "ğŸ”„ æ­¥éª¤4: å¢åˆ æ”¹æ“ä½œæµ‹è¯•"
    
    # åˆ›å»ºå¢åˆ æ”¹æµ‹è¯•è„šæœ¬
    local test_equipment_id=$((RANDOM % 1000 + 9000))
    cat > /tmp/crud_operations.sql << EOF
-- æ’å…¥æµ‹è¯•æ•°æ®åˆ°sgcc_power.power_monitoringè¡¨
INSERT INTO sgcc_power.power_monitoring (
    monitoring_id, equipment_id, voltage_a, voltage_b, voltage_c, 
    current_a, current_b, current_c, power_active, power_reactive, 
    frequency, temperature, humidity, monitoring_time
) VALUES 
  ($test_equipment_id, $test_equipment_id, 220.5, 219.8, 221.2, 15.2, 15.1, 15.3, 3350.0, 450.0, 50.01, 25.5, 60.2, NOW()),
  ($((test_equipment_id+1)), $((test_equipment_id+1)), 218.3, 218.1, 218.9, 14.8, 14.7, 14.9, 3230.0, 420.0, 50.02, 26.5, 58.0, NOW()),
  ($((test_equipment_id+2)), $((test_equipment_id+2)), 225.1, 224.8, 225.3, 16.1, 16.0, 16.2, 3625.0, 480.0, 49.99, 24.0, 62.0, NOW());

-- æ›´æ–°æµ‹è¯•æ•°æ®
UPDATE sgcc_power.power_monitoring SET temperature = 35.0, power_active = 3400.0 WHERE equipment_id = $test_equipment_id;

-- åˆ é™¤æµ‹è¯•æ•°æ®
DELETE FROM sgcc_power.power_monitoring WHERE equipment_id = $((test_equipment_id+2));
EOF
    
    # æ‰§è¡Œå¢åˆ æ”¹æ“ä½œ
    log_info "æ‰§è¡Œå¢åˆ æ”¹æ“ä½œ..."
    if docker exec -i postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db < /tmp/crud_operations.sql; then
        log_success "âœ… å¢åˆ æ”¹æ“ä½œæ‰§è¡ŒæˆåŠŸ"
        
        # ç­‰å¾…CDCåŒæ­¥
        log_info "ç­‰å¾…CDCåŒæ­¥..."
        sleep 30
        
        # éªŒè¯åŒæ­¥ç»“æœ
        log_info "éªŒè¯CDCåŒæ­¥ç»“æœ..."
        validate_data
        
    else
        log_error "âŒ å¢åˆ æ”¹æ“ä½œæ‰§è¡Œå¤±è´¥"
    fi
}

# æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡å‡½æ•°
calculate_metrics() {
    log_info "ğŸ“ˆ æ­¥éª¤5: æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡"
    
    local test_end_time=$(date +%s)
    local total_duration=$((test_end_time - TEST_START_TIME))
    
    # è·å–Flinkä½œä¸šä¿¡æ¯
    log_info "è·å–Flinkä½œä¸šä¿¡æ¯..."
    local running_jobs=$(docker exec jobmanager-sgcc /opt/flink/bin/flink list | grep -c "RUNNING" || echo "0")
    
    # è®¡ç®—ååé‡
    local throughput=0
    if [[ $total_duration -gt 0 ]]; then
        throughput=$((metrics[total_records_processed] / total_duration))
    fi
    
    # è¾“å‡ºæ€§èƒ½æŒ‡æ ‡
    cat >> "$TEST_REPORT_FILE" << EOF

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»è€—æ—¶ | ${total_duration}ç§’ |
| å¤„ç†è®°å½•æ•° | ${metrics[total_records_processed]} |
| åˆ›å»ºä½œä¸šæ•° | ${metrics[total_jobs_created]} |
| å½“å‰è¿è¡Œä½œä¸šæ•° | ${running_jobs} |
| æµ‹è¯•åœºæ™¯æ•° | ${metrics[total_test_scenarios]} |
| æˆåŠŸåœºæ™¯æ•° | ${metrics[successful_scenarios]} |
| å¤±è´¥åœºæ™¯æ•° | ${metrics[failed_scenarios]} |
| æ•°æ®ååé‡ | ${throughput} è®°å½•/ç§’ |
| æˆåŠŸç‡ | $(( metrics[successful_scenarios] * 100 / metrics[total_test_scenarios] ))% |

## ğŸ”§ ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

EOF
    
    # è·å–å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ
    log_info "è·å–å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ..."
    docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" >> "$TEST_REPORT_FILE"
    
    # è¾“å‡ºåˆ°ç»ˆç«¯
    log_success "ğŸ“Š æµ‹è¯•å®Œæˆç»Ÿè®¡ï¼š"
    log_success "  - æ€»è€—æ—¶: ${total_duration}ç§’"
    log_success "  - å¤„ç†è®°å½•æ•°: ${metrics[total_records_processed]}"
    log_success "  - åˆ›å»ºä½œä¸šæ•°: ${metrics[total_jobs_created]}"
    log_success "  - æˆåŠŸåœºæ™¯æ•°: ${metrics[successful_scenarios]}/${metrics[total_test_scenarios]}"
    log_success "  - æ•°æ®ååé‡: ${throughput} è®°å½•/ç§’"
}

# æ¸…ç†å‡½æ•°
cleanup() {
    log_info "ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    rm -f /tmp/validate_fluss_data.sql /tmp/crud_operations.sql
}

# ä¸»å‡½æ•°
main() {
    echo -e "${BLUE}ğŸš€ SGCC Fluss ä¸€é”®å¯åŠ¨å…¨é“¾è·¯éªŒè¯æµ‹è¯•${NC}"
    echo -e "${BLUE}=================================================${NC}"
    
    # åˆå§‹åŒ–æµ‹è¯•æŠ¥å‘Š
    init_test_report
    
    # æ‰§è¡Œæµ‹è¯•æµç¨‹
    start_environment
    validate_data
    run_business_scenarios
    run_crud_operations
    calculate_metrics
    cleanup
    
    # å®Œæˆä¿¡æ¯
    log_success "ğŸ‰ å…¨é“¾è·¯éªŒè¯æµ‹è¯•å®Œæˆï¼"
    log_success "ğŸ“„ è¯¦ç»†æŠ¥å‘Š: $TEST_REPORT_FILE"
    
    echo -e "${GREEN}ğŸ‰ æµ‹è¯•å®Œæˆï¼è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: $TEST_REPORT_FILE${NC}"
}

# æ•è·ä¸­æ–­ä¿¡å·
trap cleanup EXIT

# æ‰§è¡Œä¸»å‡½æ•°
main "$@" 