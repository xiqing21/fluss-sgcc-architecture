# 🔴 **Fluss项目实现问题记录与解决方案**

## 🔴 **核心技术突破：AI与Flink SQL CLI交互**

### 技术限制分析
- ✅ AI可以读取CLI交互端的输出消息
- ❌ AI无法向交互式CLI发送输入命令
- ❌ AI无法保持持久的交互会话

### 🔴 **解决方案分类**

#### 方案1：批量执行多个SQL语句 - 使用`-f`参数
```bash
# 适用场景：需要执行多个SQL语句
# 原因：Flink SQL CLI不支持一次性执行多个SQL语句
docker exec jobmanager-sgcc /opt/flink/bin/sql-client.sh -f /opt/flink/script.sql
```

#### 方案2：单个SQL语句测试 - 使用Here Document
```bash
# 适用场景：平时测试单个SQL语句
# 优势：无需创建临时文件，直接交互
docker exec -i jobmanager-sgcc /opt/flink/bin/sql-client.sh <<EOF
SET 'sql-client.execution.result-mode' = 'tableau';
SHOW TABLES;
EOF
```

#### 方案3：自动超时查询 - 使用timeout命令
```bash
# 适用场景：避免流式查询一直等待
# 解决SELECT查询卡住问题
timeout 10s docker exec -i jobmanager-sgcc /opt/flink/bin/sql-client.sh <<EOF
SET 'sql-client.execution.result-mode' = 'tableau';
SELECT * FROM streaming_table LIMIT 5;
EOF
```

### 🔴 **TABLEAU模式的正确理解**

```sql
-- 🔴 重要纠正：TABLEAU模式的真正作用
-- 默认table模式会进入专门的显示终端，需要手动按q退出
-- tableau模式让终端测试数据时直接打印结果，无需手动退出
-- 可选模式：table、tableau、changelog
SET 'sql-client.execution.result-mode' = 'tableau';
```

---

## 🔴 **问题分类与解决方案**

### 1. **Docker容器和网络问题**

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 容器名称错误 | 容器命名不一致 | 使用正确容器名：`jobmanager-sgcc` |
| 网络连接问题 | 不同项目使用不同网络 | 使用正确hostname：`coordinator-server-sgcc:9123` |

### 2. **JAR包缺失问题**

| 问题 | 错误信息 | 解决方案 |
|------|----------|----------|
| CDC连接器缺失 | `Could not find any factory for identifier 'postgres-cdc'` | 复制JAR包并重启所有Flink容器 |

```bash
# 必须重启所有容器加载新JAR包
docker restart jobmanager-sgcc taskmanager-sgcc-1 taskmanager-sgcc-2
```

### 3. **PostgreSQL CDC配置问题**

| 问题 | 错误信息 | 解决方案 |
|------|----------|----------|
| 缺少slot.name | `Missing required options: slot.name` | 添加`'slot.name' = 'unique_name'` |
| 数据库凭据错误 | `role "postgres" does not exist` | 使用正确凭据：`sgcc_user/sgcc_pass_2024` |
| **🔴 decoderbufs插件缺失** | `could not access file "decoderbufs": No such file or directory` | **使用pgoutput解码器** |

#### 🔴 **重大发现：PostgreSQL解码器问题**

**问题现象：**
```
ERROR: could not access file "decoderbufs": No such file or directory
Job状态: RESTARTING (持续重启)
```

**根本原因：**
- PostgreSQL CDC默认使用`decoderbufs`插件
- 标准PostgreSQL容器没有安装此插件
- 导致CDC作业无法启动

**🔴 关键解决方案：**
```sql
CREATE TABLE cdc_source (...) WITH (
    'connector' = 'postgres-cdc',
    -- 其他配置...
    'decoding.plugin.name' = 'pgoutput'  -- 🔴 使用PostgreSQL内置解码器
);
```

**技术对比：**
| 解码器 | 优势 | 缺点 | 适用场景 |
|--------|------|------|----------|
| `decoderbufs` | 性能更好 | 需要安装插件 | 生产环境，自定义PostgreSQL |
| `pgoutput` | 内置无需安装 | 性能略低 | 标准容器，快速开发测试 |

### 4. **Fluss Catalog问题**

| 问题 | 错误信息 | 解决方案 |
|------|----------|----------|
| 元数据列不支持 | `Metadata column not supported` | 去掉所有METADATA列定义 |
| 跨catalog查询错误 | 表未找到 | 使用完整路径：`catalog.database.table` |
| **🔴 Catalog不持久化** | `A catalog with name [fluss_catalog] does not exist` | **每次会话重新创建catalog** |

#### 🔴 **Catalog生命周期问题**

**问题现象：**
- 在一个SQL会话中创建的catalog在另一个会话中不存在
- 需要重复创建fluss_catalog

**解决方案：**
```sql
-- 每个新会话都要重新创建catalog
CREATE CATALOG fluss_catalog WITH (
    'type' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);
```

### 5. **CDC流式查询问题**

#### 🔴 **核心问题：SELECT查询卡住**
**根本原因：**
- CDC表是**流式数据源**
- SELECT查询是**连续查询**
- 会持续监听数据变化，永远不会"完成"

**解决方案分类：**

| 场景 | 问题 | 解决方案 |
|------|------|----------|
| **数据流作业** | INSERT语句正常 | 使用INSERT INTO启动数据流 |
| **数据验证** | SELECT卡住 | 使用timeout命令限制时间 |
| **流式排序** | ORDER BY不支持 | 去掉ORDER BY子句 |

**🔴 实用解决方案：**
```bash
# 方案1：自动超时（推荐）
timeout 10s ./改进版SQL执行脚本.sh "SELECT * FROM streaming_table LIMIT 5"

# 方案2：避免直接查询CDC表
INSERT INTO target_table SELECT * FROM cdc_table;  # 启动数据流
SELECT COUNT(*) FROM target_table;  # 查询目标表（在另一个会话中）
```

---

## 🔴 **标准操作流程**

### 🔴 **完整CDC数据流建立流程**

```bash
# 1. 确保JAR包存在并重启Flink集群
docker cp fluss/jars/flink-sql-connector-postgres-cdc-3.1.1.jar jobmanager-sgcc:/opt/flink/lib/
docker restart jobmanager-sgcc taskmanager-sgcc-1 taskmanager-sgcc-2

# 2. 执行完整CDC配置（包含pgoutput解码器）
./执行SQL脚本.sh 修复CDC配置.sql

# 3. 验证作业状态
docker exec jobmanager-sgcc curl -s http://localhost:8081/jobs | grep -i running

# 4. 测试数据同步（带超时）
timeout 15s ./改进版SQL执行脚本.sh "
CREATE CATALOG fluss_catalog WITH ('type' = 'fluss', 'bootstrap.servers' = 'coordinator-server-sgcc:9123');
USE CATALOG fluss_catalog; USE fluss;
SELECT * FROM power_equipment_fluss_target LIMIT 3;
"
```

### 单个SQL测试流程
```bash
# 普通查询
./改进版SQL执行脚本.sh "SHOW TABLES"

# 流式查询（带超时）
timeout 10s ./改进版SQL执行脚本.sh "SELECT * FROM streaming_table LIMIT 5"
```

### 批量SQL执行流程
```bash
./执行SQL脚本.sh script.sql
```

---

## 🔴 **重要配置参数**

### PostgreSQL CDC必要参数（修复版）
作业仍在RESTARTING状态。让我检查JobManager的日志，看看CDC作业是否有错误：
docker logs jobmanager-sgcc --tail 20 | grep -E "(ERROR|Exception|WARN|CDC|postgres|fluss)" || docker logs jobmanager-sgcc --tail 20
错误信息显示：
ERROR: could not access file "decoderbufs": No such file or directory
这是因为PostgreSQL CDC需要使用WAL-level logical replication，但是缺少了decoderbufs插件。这是PostgreSQL CDC的一个常见问题。
有几种解决方案：
安装decoderbufs插件
使用另一个解码插件，比如pgoutput（PostgreSQL内置的）
让我修改CDC配置，使用pgoutput解码器，这是PostgreSQL内置的，不需要额外安装插件。

```sql
) WITH (
    'connector' = 'postgres-cdc',
    'hostname' = 'postgres-sgcc-source',
    'port' = '5432',
    'username' = 'sgcc_user',
    'password' = 'sgcc_pass_2024',
    'database-name' = 'sgcc_source_db',
    'schema-name' = 'sgcc_power',
    'table-name' = 'power_equipment',
    'slot.name' = 'unique_slot_name',
    'decoding.plugin.name' = 'pgoutput'  -- 🔴 关键修复
);
```

### Fluss连接器必要参数
```sql
) WITH (
    'connector' = 'fluss',
    'bootstrap.servers' = 'coordinator-server-sgcc:9123'
);
```

---

## 🔴 **常见错误速查表**

| 错误关键词 | 问题原因 | 快速解决 |
|------------|----------|----------|
| `postgres-cdc` not found | JAR包缺失 | 复制CDC JAR包并重启 |
| `slot.name` missing | CDC配置不完整 | 添加slot.name参数 |
| `decoderbufs` not found | **解码器插件缺失** | **添加`'decoding.plugin.name' = 'pgoutput'`** |
| `Metadata column not supported` | Fluss不支持元数据列 | 去掉METADATA列 |
| `role does not exist` | 数据库凭据错误 | 检查用户名密码 |
| 查询卡住不动 | 直接查询CDC表 | 使用timeout或改为INSERT INTO目标表 |
| `fluss_catalog does not exist` | Catalog不持久化 | 每次会话重新创建catalog |
| `Sort on non-time-attribute` | 流式查询排序限制 | 去掉ORDER BY子句 |

---

## 🔴 **成功验证标志**

### ✅ **CDC数据流成功的标志**
1. **作业状态正常**：`Job状态: RUNNING`
2. **数据同步成功**：流式查询显示 `| +I |` 操作
3. **表创建成功**：`SHOW TABLES` 返回目标表名
4. **连接器工作正常**：无decoderbufs相关错误

### ✅ **完整测试验证**
```bash
# 1. 插入测试数据
docker exec postgres-sgcc-source psql -U sgcc_user -d sgcc_source_db -c "
INSERT INTO sgcc_power.power_equipment (equipment_id, equipment_name, equipment_type) 
VALUES (9999, 'CDC验证测试', '测试设备');
"

# 2. 验证同步（带超时）
timeout 10s ./改进版SQL执行脚本.sh "
CREATE CATALOG fluss_catalog WITH ('type' = 'fluss', 'bootstrap.servers' = 'coordinator-server-sgcc:9123');
USE CATALOG fluss_catalog; USE fluss;
SELECT equipment_id, equipment_name FROM power_equipment_fluss_target WHERE equipment_id = 9999 LIMIT 1;
"
```

---

**🔴 核心要点：**
1. **tableau模式**：避免手动按q退出，直接打印结果
2. **Here Document + timeout**：解决流式查询卡住问题
3. **pgoutput解码器**：解决decoderbufs插件缺失问题
4. **catalog重新创建**：每次新会话都要重新创建fluss_catalog
5. **避免直接查询CDC表**：会导致卡住，应该INSERT到目标表后查询 